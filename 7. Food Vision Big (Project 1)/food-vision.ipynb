{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Project inspired from this paper\n**<a href= \"https://www.researchgate.net/publication/304163308_DeepFood_Deep_Learning-Based_Food_Image_Recognition_for_Computer-Aided_Dietary_Assessment\"> DeepFood</a>**","metadata":{}},{"cell_type":"markdown","source":"### Get helper functions","metadata":{}},{"cell_type":"code","source":"!wget https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py","metadata":{"execution":{"iopub.status.busy":"2023-06-13T16:01:40.386209Z","iopub.execute_input":"2023-06-13T16:01:40.386637Z","iopub.status.idle":"2023-06-13T16:01:41.783610Z","shell.execute_reply.started":"2023-06-13T16:01:40.386601Z","shell.execute_reply":"2023-06-13T16:01:41.781911Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"--2023-06-13 16:01:41--  https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.111.133, 185.199.108.133, ...\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 10246 (10K) [text/plain]\nSaving to: ‘helper_functions.py’\n\nhelper_functions.py 100%[===================>]  10.01K  --.-KB/s    in 0s      \n\n2023-06-13 16:01:41 (47.3 MB/s) - ‘helper_functions.py’ saved [10246/10246]\n\n","output_type":"stream"}]},{"cell_type":"code","source":"from helper_functions import create_tensorboard_callback, plot_loss_curves, compare_historys","metadata":{"execution":{"iopub.status.busy":"2023-06-13T16:02:27.603227Z","iopub.execute_input":"2023-06-13T16:02:27.605421Z","iopub.status.idle":"2023-06-13T16:02:52.086680Z","shell.execute_reply.started":"2023-06-13T16:02:27.605291Z","shell.execute_reply":"2023-06-13T16:02:52.085046Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Tensoflow Datasets","metadata":{}},{"cell_type":"code","source":"import tensorflow_datasets as tfds","metadata":{"execution":{"iopub.status.busy":"2023-06-13T16:07:27.246155Z","iopub.execute_input":"2023-06-13T16:07:27.248832Z","iopub.status.idle":"2023-06-13T16:07:31.579219Z","shell.execute_reply.started":"2023-06-13T16:07:27.248748Z","shell.execute_reply":"2023-06-13T16:07:31.577720Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"(train_data, test_data), ds_info = tfds.load(name=\"food101\",\n                                            split=[\"train\", \"validation\"],\n                                            shuffle_files=True,\n                                            as_supervised=True,\n                                            with_info=True)","metadata":{"execution":{"iopub.status.busy":"2023-06-13T16:10:24.374031Z","iopub.execute_input":"2023-06-13T16:10:24.374448Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"\u001b[1mDownloading and preparing dataset 4.65 GiB (download: 4.65 GiB, generated: Unknown size, total: 4.65 GiB) to /root/tensorflow_datasets/food101/2.0.0...\u001b[0m\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Dl Completed...: 0 url [00:00, ? url/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"88b4f0755cf84e86a360a37d3f7441ba"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Dl Size...: 0 MiB [00:00, ? MiB/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3c7fc318fe4b4933ad0ec46d3274cf0e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Extraction completed...: 0 file [00:00, ? file/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"060154322bed49a3a3ad10a8469f0f68"}},"metadata":{}}]},{"cell_type":"code","source":"ds_info.features","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class_names = ds_info.features[\"label\"].names\nclass_names[:10]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}